<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Hewlett Packard Enterprise" /><link rel="canonical" href="https://scod.hpedev.io/csi_driver/standalone_nfs.html" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <meta property="og:title" content="HPE Storage Container Orchestrator Documentation (SCOD)"/>
    <meta property="og:description" content="This is an umbrella documentation project for all container integrations surrounding HPE block, file and object storage. Tailored for IT ops, developers and technology partners."/>
    <meta property="og:locale" content="en_US"/>
    <meta property="og:url" content="https://scod.hpedev.io"/>
    <meta property="og:type" content="website"/>
    <meta property="og:image" content="https://scod.hpedev.io/img/hpe-social-og-image01.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="630"/>
    
    <title>Standalone NFS Server - SCOD.HPEDEV.IO</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../css/hpedev.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Standalone NFS Server";
        var mkdocs_page_input_path = "csi_driver/standalone_nfs.md";
        var mkdocs_page_url = "/csi_driver/standalone_nfs.html";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-PC28RTKKTW"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', "G-PC28RTKKTW");
      </script>
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="..">
          <img src="../img/hpe.png" class="logo" alt="Logo"/>
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">WELCOME</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../welcome/index.html">Get started!</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">HPE CSI DRIVER FOR KUBERNETES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="index.html">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="deployment.html">Deployment</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="using.html">Using</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Container Storage Providers</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="container_storage_provider/hpe_alletra_storage_mp_b10000/index.html">HPE Alletra Storage MP B10000, Alletra 9000, Primera and 3PAR</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="container_storage_provider/hpe_alletra_storage_mp_b10000_file_service/index.html">HPE Alletra Storage MP B10000 File Service</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="container_storage_provider/hpe_alletra_6000/index.html">HPE Alletra 5000/6000 and Nimble Storage</a>
                </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="monitor.html">Pod Monitor</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="operations.html">Auxiliary Operations</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="diagnostics.html">Diagnostics</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" >Partner Ecosystems</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="partners/hpe_morpheus/install.html">HPE Morpheus Kubernetes Service</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/hpe_ezmeral/install.html">HPE Ezmeral Runtime Enterprise</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/amazon_eks_anywhere/index.html">Amazon EKS Anywhere</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/canonical/index.html">Canonical</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/cohesity/index.html">Cohesity</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/commvault/index.html">Commvault</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/kasten/index.html">Veeam Kasten</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/mirantis/index.html">Mirantis</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/redhat_openshift/index.html">Red Hat OpenShift</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/suse_virtualization/index.html">SUSE Virtualization</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/suse_rancher/index.html">SUSE Rancher</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/tkgi/index.html">Tanzu TKGI</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="partners/vmware/index.html">VMware</a>
                </li>
    </ul>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">HPE COSI DRIVER FOR KUBERNETES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../cosi_driver/index.html">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cosi_driver/deployment.html">Deployment</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cosi_driver/using.html">Using</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../cosi_driver/diagnostics.html">Diagnostics</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">HPE GREENLAKE FOR FILE STORAGE</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../filex_csi_driver/index.html">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../filex_csi_driver/deployment.html">Deployment</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../filex_csi_driver/using.html">Using</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">LEARN</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../learn/persistent_storage/index.html">Persistent Storage for Kubernetes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../learn/introduction_to_containers/index.html">For HPE partners:<br />&nbsp;&nbsp; Introduction to Containers</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../learn/csi_primitives/index.html">Introduction to CSI Primitives</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../learn/video_gallery/index.html">Video Gallery</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../learn/csi_workshop/index.html">Interactive CSI Workshop</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">COMMUNITY</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="https://developer.hpe.com">HPE Developer</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://slack.hpedev.io">Sign up to HPE Developer on Slack</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://github.com/hpe-storage/scod/issues/new?title=I have some feedback on SCOD">Got feedback?</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">EXTERNAL LINKS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="https://github.com/hpe-storage/scod">SCOD on GitHub</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://github.com/hpe-storage">HPE Storage on GitHub</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="https://hpe.com/storage/containers">Storage for Containers on hpe.com</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">LEGAL</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/contributing/index.html">Contributing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/support/index.html">Support</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/license/index.html">License</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/notices/index.html">Notices</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">LEGACY DRIVERS AND PLUGINS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../legacy/index.html">Docker, FlexVolume and CSPs</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">SCOD.HPEDEV.IO</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Standalone NFS Server</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="standalone_nfs_server">Standalone NFS Server<a class="headerlink" href="#standalone_nfs_server" title="Permanent link">&para;</a></h1>
<p>In certain situations is desirable to run the NFS Server Provisioner image without the dual <code>PersistentVolumeClaim</code> (PVC) semantic in a more static fashion on top of a <code>PVC</code> provisioned by a non-HPE CSI Driver <code>StorageClass</code>.</p>
<div class="admonition caution">
<p class="admonition-title">Notice</p>
<p>Since HPE CSI Driver for Kubernetes v2.4.1, this functionality is built into the CSI driver. See <a href="using.html#using_a_foreign_storageclass">Using a Foreign StorageClass</a> how to use it.</p>
</div>
<div class="toc">
<ul>
<li><a href="#standalone_nfs_server">Standalone NFS Server</a><ul>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#create_a_workspace">Create a Workspace</a></li>
<li><a href="#create_an_nfs_server">Create an NFS Server</a><ul>
<li><a href="#environmentproperties">environment.properties</a></li>
<li><a href="#kustomizationyaml">kustomization.yaml</a></li>
<li><a href="#change_the_default_fsgroup">Change the default fsGroup</a></li>
</ul>
</li>
<li><a href="#mounting_the_nfs_server">Mounting the NFS Server</a><ul>
<li><a href="#inline_declaration">Inline Declaration</a></li>
<li><a href="#static_provisioning">Static Provisioning</a></li>
</ul>
</li>
<li><a href="#expand_pvc">Expand PVC</a></li>
<li><a href="#deleting_the_nfs_server">Deleting the NFS Server</a></li>
</ul>
</li>
</ul>
</div>
<h2 id="limitations">Limitations<a class="headerlink" href="#limitations" title="Permanent link">&para;</a></h2>
<ul>
<li>The standalone NFS server is not part of the HPE CSI Driver and should be considered a standalone Kubernetes application altogether. The HPE CSI Driver NFS Server Provisioner NFS servers may co-exist on the same cluster and <code>Namespace</code> without risk of conflict but not recommended.</li>
<li>The <a href="monitor.html">Pod Monitor</a> which normally monitors <code>Pods</code> status for the "NodeLost" condition is not included with the standalone NFS server and recovery is at the mercy of the underlying storage platform and driver.</li>
<li>Support is limited on the standalone NFS server and only available to select users.</li>
</ul>
<h2 id="prerequisites">Prerequisites<a class="headerlink" href="#prerequisites" title="Permanent link">&para;</a></h2>
<p>It's assumed during the creation steps that a Kubernetes cluster is available with enough permissions to deploy privileged <code>Pods</code> with <code>SYS_ADMIN</code> and <code>DAC_READ_SEARCH</code> capabilities. All steps are run in a terminal with <code>kubectl</code> and <code>git</code> in in the path.</p>
<ul>
<li>A default <code>StorageClass</code> declared on the cluster</li>
<li>Worker nodes that will serve the NFS exports <em>must</em> be labeled with <code>csi.hpe.com/hpe-nfs: "true"</code></li>
<li><code>kubectl</code> and Kubernetes v1.21 or newer</li>
</ul>
<h2 id="create_a_workspace">Create a Workspace<a class="headerlink" href="#create_a_workspace" title="Permanent link">&para;</a></h2>
<p>NFS server configurations are managed with the kustomize templating system. Clone this repository to get started and change working directory.</p>
<p> <pre><code class=text>git clone https://github.com/hpe-storage/scod
cd scod/docs/csi_driver/examples/standalone_nfs
</code></pre></p>
<p>In the current directory, various manifests and configuration directives exist to deploy and manage NFS servers.</p>
<p>Run <code>tree .</code> in the current directory: </p>
<p> <pre><code class=text>.
├── base
│   ├── configmap.yaml
│   ├── deployment.yaml
│   ├── environment.properties
│   ├── kustomization.yaml
│   ├── pvc.yaml
│   ├── service.yaml
│   └── values.yaml
└── overlays
    └── example
        ├── deployment.yaml
        ├── environment.properties
        └── kustomization.yaml

4 directories, 10 files
</code></pre></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The current directory is now the "home" for the remainder of this guide.</p>
</div>
<h2 id="create_an_nfs_server">Create an NFS Server<a class="headerlink" href="#create_an_nfs_server" title="Permanent link">&para;</a></h2>
<p>Copy the "example" overlay into a new directory. In the examples "my-server" is used.</p>
<p> <pre><code class=text>cp -a overlays/example overlays/my-server
</code></pre></p>
<p>Edit both "environment.properties" and "kustomization.yaml" in the newly created overlay. Also pay attention to if the remote <code>Pods</code> mounting the NFS export are running as a non-root user, if that's the case, the group ID is needed of those <code>Pods</code> (customizable per NFS server).</p>
<h3 id="environmentproperties">environment.properties<a class="headerlink" href="#environmentproperties" title="Permanent link">&para;</a></h3>
<p> <pre><code class=text># This is the domain associated with worker node (not inter-cluster DNS)
CLUSTER_NODE_DOMAIN_NAME=my-domain.example.com

# The size of the backend RWO claim
PERSISTENCE_SIZE=16Gi

# Default resource limits for the NFS server
NFS_SERVER_CPU_LIMIT=1
NFS_SERVER_MEMORY_LIMIT=2Gi
</code></pre></p>
<p>The "CLUSTER_NODE_DOMAIN_NAME" variable refers to the DNS domain name that the worker node is resolvable in, not the Kubernetes cluster DNS.</p>
<p>The "PERSISTENCE_SIZE" is the backend <code>PVC</code> size expressed in the same format accepted by a <code>PVC</code>.</p>
<p>Configuring resource limits are optional but recommended for high performance workloads.</p>
<h3 id="kustomizationyaml">kustomization.yaml<a class="headerlink" href="#kustomizationyaml" title="Permanent link">&para;</a></h3>
<p>Change the resource prefix in "kustomization.yaml" either with an editor or <code>sed</code>:</p>
<p> <pre><code class=text>sed -i&quot;&quot; 's/example-/my-server-/g' overlays/my-server/kustomization.yaml
</code></pre></p>
<div class="admonition seealso">
<p class="admonition-title">Seealso</p>
<p>If the NFS server needs to be deployed in a different <code>Namespace</code> than the current, edit and uncomment the "namespace" parameter in <code>overlays/my-server/kustomization.yaml</code>.</p>
</div>
<h3 id="change_the_default_fsgroup">Change the default fsGroup<a class="headerlink" href="#change_the_default_fsgroup" title="Permanent link">&para;</a></h3>
<p>The default "fsGroup" is mapped to "nobody" (gid=65534) which allows remote <code>Pods</code> run as the root user to write in the NFS export. This may not be desirable as best practices dictate that <code>Pods</code> should run with a user id larger than 99.</p>
<p>To allow user <code>Pods</code> to write in the export, edit <code>overlays/my-server/deployment.yaml</code> and change the "fsGroup" to the corresponding gid running in the remote <code>Pod</code>.</p>
<p> <pre><code class=text>apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpe-nfs
spec:
  template:
    spec:
      securityContext:
        fsGroup: 65534
        fsGroupChangePolicy: OnRootMismatch
</code></pre></p>
<p>Deploy the NFS server by issuing <code>kubectl apply -k overlays/my-server</code>:</p>
<p> <pre><code class=text>configmap/my-server-hpe-nfs-conf created
configmap/my-server-local-conf-97898bftbh created
service/my-server-hpe-nfs created
persistentvolumeclaim/my-server-hpe-nfs created
deployment.apps/my-server-hpe-nfs created
</code></pre></p>
<p>Inspect the resources with <code>kubectl get -k overlays/my-server</code>:</p>
<p> <pre><code class=text>NAME                                        DATA   AGE
configmap/my-server-hpe-nfs-conf            1      59s
configmap/my-server-local-conf-97898bftbh   2      59s

NAME                        TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                                                               AGE
service/my-server-hpe-nfs   ClusterIP   10.100.200.11   &lt;none&gt;        49000/TCP,2049/TCP,2049/UDP,32803/TCP,32803/UDP,20048/TCP,20048/UDP,111/TCP,111/UDP,662/TCP,662/UDP,875/TCP,875/UDP   59s

NAME                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/my-server-hpe-nfs   Bound    pvc-ae943116-d0af-4696-8b1b-1dcf4316bdc2   18Gi       RWO            vsphere-sc     58s

NAME                                READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/my-server-hpe-nfs   1/1     1            1           59s
</code></pre></p>
<p>Make a note of the IP address assigned to "service/my-server-hpe-nfs", that is the IP address needed to mount the NFS export.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If the Kubernetes cluster DNS service is resolvable from the worker node host OS, it possible to use the cluster DNS address to mount the <code>Service</code>, in this example that would be "my-server-hpe-nfs.default.svc.cluster.local".</p>
</div>
<h2 id="mounting_the_nfs_server">Mounting the NFS Server<a class="headerlink" href="#mounting_the_nfs_server" title="Permanent link">&para;</a></h2>
<p>There are two ways to mount the NFS server.</p>
<ol>
<li>Inline declaration of where to find the NFS server and NFS Export</li>
<li>Statically creating a <code>PersistentVolume</code> with the NFS server details and mount options and manually claiming the <code>PV</code> with a <code>PVC</code> using the <code>.spec.volumeName</code> parameter</li>
</ol>
<h3 id="inline_declaration">Inline Declaration<a class="headerlink" href="#inline_declaration" title="Permanent link">&para;</a></h3>
<p>This is the most elegant solution as it does not require any intermediary <code>PVC</code> or <code>PV</code> and directly refers to the NFS server within a workload stanza.</p>
<p>This is an example from a <code>StatefulSet</code> workload controller having multiple replicas.</p>
<p> <pre><code class=text>...
spec:
  replicas: 3
  template:
    ...
    spec:
      containers:
        volumeMounts:
        - name: vol
          mountPath: /vol
      ...
      volumes:
      - name: vol
        nfs:
          server: 10.100.200.11
          path: /export
</code></pre></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Replace <code>.spec.template.spec.volumes[].nfs.server</code> with IP address from the actual <code>Service</code> IP address and not the examples.</p>
</div>
<h3 id="static_provisioning">Static Provisioning<a class="headerlink" href="#static_provisioning" title="Permanent link">&para;</a></h3>
<p>Refer to the <a href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs">official Kubernetes documentation</a> for the built-in NFS client on how to perform static provisioning of NFS <code>PVs</code> and <code>PVCs</code>.</p>
<h2 id="expand_pvc">Expand PVC<a class="headerlink" href="#expand_pvc" title="Permanent link">&para;</a></h2>
<p>If the <code>StorageClass</code> and underlying CSI driver supports volume expansion, simply edit <code>overlays/my-server/environment.properties</code> with the new (larger) size and issue <code>kubectl apply -k overlays/my-server</code> to expand the volume.</p>
<h2 id="deleting_the_nfs_server">Deleting the NFS Server<a class="headerlink" href="#deleting_the_nfs_server" title="Permanent link">&para;</a></h2>
<p>Ensure no workloads have active mounts against the NFS server <code>Service</code>. If there are, those <code>Pods</code> will be stuck indefinitely. </p>
<p>Run <code>kubectl delete -k overlays/my-server</code>:</p>
<p> <pre><code class=text>configmap &quot;my-server-hpe-nfs-conf&quot; deleted
configmap &quot;my-server-local-conf-97898bftbh&quot; deleted
service &quot;my-server-hpe-nfs&quot; deleted
persistentvolumeclaim &quot;my-server-hpe-nfs&quot; deleted
deployment.apps &quot;my-server-hpe-nfs&quot; deleted
</code></pre></p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Unless the <code>StorageClass</code> "reclaimPolicy" is set to "Retain". The underlying <code>PV</code> will be deleted from the cluster and data needs to be restored from backups if needed.</p>
</div>
              
            </div>
          </div>

<footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
    <p>Copyright 2020-2025 Hewlett Packard Enterprise Development LP<br />Give <a href="https://github.com/hpe-storage/scod/issues/new?title=csi_driver/standalone_nfs.html">feedback</a> on this page.</p>
    
  </div>
</footer>

        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/hpe-storage/scod" class="fa fa-code-fork" style="color: #fcfcfc"> hpe-storage/scod</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
